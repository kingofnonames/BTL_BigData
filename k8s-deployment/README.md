# Kubernetes Deployment - Triá»ƒn khai há»‡ thá»‘ng BigData trÃªn K8s

HÆ°á»›ng dáº«n triá»ƒn khai toÃ n bá»™ há»‡ thá»‘ng thu tháº­p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chá»©ng khoÃ¡n lÃªn Kubernetes cluster.

---

## ğŸ“‹ Giá»›i thiá»‡u

ThÆ° má»¥c nÃ y chá»©a táº¥t cáº£ manifest files cáº§n thiáº¿t Ä‘á»ƒ deploy há»‡ thá»‘ng Lambda Architecture (Batch Layer + Speed Layer) lÃªn Kubernetes:

- **Infrastructure Layer**: Kafka, Zookeeper, HDFS (NameNode, DataNode), Elasticsearch, Spark
- **Batch Layer**: Crawler batch, Kafka-to-HDFS jobs, Daily OHLCV, Analyst, MLlib
- **Speed Layer**: Speed crawler, OHLCV speed processor
- **Orchestration**: Airflow (scheduler, database)

---

## ğŸ—ï¸ Cáº¥u trÃºc thÆ° má»¥c

```
k8s-deployment/
â”œâ”€â”€ namespace.yaml              # Táº¡o namespace "bigdata"
â”‚
â”œâ”€â”€ configmap/                  # Cáº¥u hÃ¬nh táº­p trung
â”‚   â”œâ”€â”€ bigdata-config.yaml    # Config cho HDFS, Kafka, Elasticsearch, Spark
â”‚   â””â”€â”€ kafka-config.yaml      # Config riÃªng cho Kafka
â”‚
â”œâ”€â”€ secrets/                    # ThÃ´ng tin báº£o máº­t
â”‚   â””â”€â”€ airflow-secret.yaml    # Credentials cho Airflow DB
â”‚
â”œâ”€â”€ deployments/                # CÃ¡c deployment cháº¡y liÃªn tá»¥c
â”‚   â”œâ”€â”€ zookeeper-deployment.yaml
â”‚   â”œâ”€â”€ kafka-deployment.yaml
â”‚   â”œâ”€â”€ namenode-deployment.yaml
â”‚   â”œâ”€â”€ datanode-deployment.yaml
â”‚   â”œâ”€â”€ elasticsearch-deployment.yaml
â”‚   â”œâ”€â”€ spark-master-deployment.yaml
â”‚   â”œâ”€â”€ spark-worker-deployment.yaml
â”‚   â”œâ”€â”€ airflow-db-deployment.yaml
â”‚   â”œâ”€â”€ crawler-deployment.yaml
â”‚   â”œâ”€â”€ speed-crawler-deployment.yaml
â”‚   â”œâ”€â”€ ohlcv-speed-deployment.yaml
â”‚   â”œâ”€â”€ kafka-to-hdfs-market-deployment.yaml
â”‚   â”œâ”€â”€ kafka-to-hdfs-ohlcv-deployment.yaml
â”‚   â”œâ”€â”€ daily-ohlcv-deployment.yaml
â”‚   â”œâ”€â”€ analyst-ohlcv-deployment.yaml
â”‚   â””â”€â”€ mlib-evaluate-deployment.yaml
â”‚
â”œâ”€â”€ services/                   # Expose services trong cluster
â”‚   â”œâ”€â”€ zookeeper-service.yaml
â”‚   â”œâ”€â”€ kafka-service.yaml
â”‚   â”œâ”€â”€ namenode-service.yaml
â”‚   â”œâ”€â”€ datanode-service.yaml
â”‚   â”œâ”€â”€ elasticsearch-service.yaml
â”‚   â”œâ”€â”€ spark-master-service.yaml
â”‚   â””â”€â”€ airflow-db-service.yaml
â”‚
â””â”€â”€ jobs/                       # Kubernetes CronJob hoáº·c Job (cháº¡y 1 láº§n/theo lá»‹ch)
    â”œâ”€â”€ crawler-job.yaml
    â”œâ”€â”€ kafka-to-hdfs-market-job.yaml
    â”œâ”€â”€ kafka-to-hdfs-ohlcv-job.yaml
    â”œâ”€â”€ daily-ohlcv-job.yaml
    â”œâ”€â”€ ohlcv-analysis-job.yaml
    â”œâ”€â”€ ohlch-speed-job.yaml
    â”œâ”€â”€ mlib-evaluate-job.yaml
    â””â”€â”€ speed-crawler-job.yaml
```

---

## ğŸ“¦ CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. Infrastructure Components

#### **Zookeeper** (`zookeeper-deployment.yaml`)
- Quáº£n lÃ½ metadata cho Kafka cluster
- Port: `2181`
- Resource: 256Mi RAM, 0.3 CPU

#### **Kafka** (`kafka-deployment.yaml`)
- Message broker cho streaming data
- Port: `9092`
- Topics: `stock.ohlcv.raw`, `stock.market.raw`, `stock.market.speed.raw`
- Resource: 768Mi RAM, 0.8 CPU

#### **HDFS NameNode** (`namenode-deployment.yaml`)
- Quáº£n lÃ½ metadata cá»§a HDFS
- Web UI: `9870`
- HDFS URI: `hdfs://namenode:8020`
- Resource: 1Gi RAM, 0.7 CPU

#### **HDFS DataNode** (`datanode-deployment.yaml`)
- LÆ°u trá»¯ dá»¯ liá»‡u thá»±c táº¿
- Resource: 1.5Gi RAM, 1.0 CPU

#### **Elasticsearch** (`elasticsearch-deployment.yaml`)
- LÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
- Port: `9200`
- Indices: `ohlcv_daily_v2`, `ohlcv_analysis`, `market_data_v1`, `stock_intraday`

#### **Spark** (`spark-master-deployment.yaml`, `spark-worker-deployment.yaml`)
- Spark Master: Äiá»u phá»‘i cÃ¡c Spark jobs
  - Web UI: `8080`, Submit: `7077`
- Spark Worker: Thá»±c thi cÃ¡c tasks
  - Resource: 2Gi RAM, 1.5 CPU

---

### 2. Batch Layer Components

#### **Crawler Batch** (`crawler-deployment.yaml`)
- Thu tháº­p dá»¯ liá»‡u OHLCV vÃ  Market Index lá»‹ch sá»­
- Gá»­i vÃ o Kafka topics: `stock.ohlcv.raw`, `stock.market.raw`
- Cháº¡y theo schedule hoáº·c trigger thá»§ cÃ´ng

#### **Kafka to HDFS - OHLCV** (`kafka-to-hdfs-ohlcv-deployment.yaml`)
- Äá»c tá»« Kafka topic `stock.ohlcv.raw`
- Ghi vÃ o HDFS: `hdfs://namenode:8020/data/ohlcv`
- Format: Parquet, partitioned by `symbol`, `interval`, `trade_date`

#### **Kafka to HDFS - Market** (`kafka-to-hdfs-market-deployment.yaml`)
- Äá»c tá»« Kafka topic `stock.market.raw`
- Ghi vÃ o HDFS: `hdfs://namenode:8020/data/market`
- Format: Parquet, partitioned by `index_code`, `trade_date`

#### **Daily OHLCV** (`daily-ohlcv-deployment.yaml`)
- Xá»­ lÃ½ dá»¯ liá»‡u OHLCV hÃ ng ngÃ y tá»« HDFS
- Ghi vÃ o Elasticsearch index: `ohlcv_daily_v2`
- Cháº¡y vá»›i Spark Submit

#### **Analyst OHLCV** (`analyst-ohlcv-deployment.yaml`)
- TÃ­nh toÃ¡n chá»‰ sá»‘ ká»¹ thuáº­t: SMA, EMA, RSI, MACD, Bollinger Bands
- Xá»­ lÃ½ incremental (chá»‰ tÃ­nh toÃ¡n dá»¯ liá»‡u má»›i)
- Ghi vÃ o Elasticsearch index: `ohlcv_analysis`

#### **MLlib Evaluate** (`mlib-evaluate-deployment.yaml`)
- Huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u
- Models: Linear Regression, Random Forest
- ÄÃ¡nh giÃ¡: RMSE, R2 Score

---

### 3. Speed Layer Components

#### **Speed Crawler** (`speed-crawler-deployment.yaml`)
- Thu tháº­p dá»¯ liá»‡u real-time (tick-by-tick)
- Gá»­i vÃ o Kafka topic: `stock.market.speed.raw`

#### **OHLCV Speed** (`ohlcv-speed-deployment.yaml`)
- Tá»•ng há»£p dá»¯ liá»‡u real-time thÃ nh náº¿n OHLCV
- Ghi vÃ o Elasticsearch index: `stock_intraday`

---

### 4. Orchestration - Airflow

#### **Airflow DB** (`airflow-db-deployment.yaml`)
- PostgreSQL database cho Airflow metadata
- Port: `5432`

---

## ğŸš€ HÆ°á»›ng dáº«n triá»ƒn khai

### YÃªu cáº§u:
- Kubernetes cluster (v1.20+)
- kubectl CLI configured
- Docker images Ä‘Ã£ build sáºµn cho cÃ¡c services

### BÆ°á»›c 1: Táº¡o namespace

```bash
kubectl apply -f namespace.yaml
```

### BÆ°á»›c 2: Táº¡o ConfigMap vÃ  Secret

```bash
# ConfigMaps
kubectl apply -f configmap/bigdata-config.yaml
kubectl apply -f configmap/kafka-config.yaml

# Secrets
kubectl apply -f secrets/airflow-secret.yaml
```

### BÆ°á»›c 3: Deploy Infrastructure (theo thá»© tá»±)

```bash
# 1. Zookeeper (cáº§n cho Kafka)
kubectl apply -f deployments/zookeeper-deployment.yaml
kubectl apply -f services/zookeeper-service.yaml

# Chá» Zookeeper ready
kubectl wait --for=condition=ready pod -l app=zookeeper -n bigdata --timeout=120s

# 2. Kafka
kubectl apply -f deployments/kafka-deployment.yaml
kubectl apply -f services/kafka-service.yaml

# 3. HDFS
kubectl apply -f deployments/namenode-deployment.yaml
kubectl apply -f services/namenode-service.yaml
kubectl apply -f deployments/datanode-deployment.yaml
kubectl apply -f services/datanode-service.yaml

# 4. Elasticsearch
kubectl apply -f deployments/elasticsearch-deployment.yaml
kubectl apply -f services/elasticsearch-service.yaml

# 5. Spark
kubectl apply -f deployments/spark-master-deployment.yaml
kubectl apply -f services/spark-master-service.yaml
kubectl apply -f deployments/spark-worker-deployment.yaml
```

### BÆ°á»›c 4: Deploy Batch Layer

```bash
# Crawler
kubectl apply -f deployments/crawler-deployment.yaml

# Kafka to HDFS
kubectl apply -f deployments/kafka-to-hdfs-ohlcv-deployment.yaml
kubectl apply -f deployments/kafka-to-hdfs-market-deployment.yaml

# Processing jobs
kubectl apply -f deployments/daily-ohlcv-deployment.yaml
kubectl apply -f deployments/analyst-ohlcv-deployment.yaml
kubectl apply -f deployments/mlib-evaluate-deployment.yaml
```

### BÆ°á»›c 5: Deploy Speed Layer

```bash
kubectl apply -f deployments/speed-crawler-deployment.yaml
kubectl apply -f deployments/ohlcv-speed-deployment.yaml
```

### BÆ°á»›c 6: Deploy Airflow (optional)

```bash
kubectl apply -f deployments/airflow-db-deployment.yaml
kubectl apply -f services/airflow-db-service.yaml
```

### BÆ°á»›c 7: Deploy Jobs (CronJob - cháº¡y theo lá»‹ch)

```bash
kubectl apply -f jobs/crawler-job.yaml
kubectl apply -f jobs/kafka-to-hdfs-ohlcv-job.yaml
kubectl apply -f jobs/daily-ohlcv-job.yaml
kubectl apply -f jobs/ohlcv-analysis-job.yaml
```

---

## ğŸ“Š Kiá»ƒm tra tráº¡ng thÃ¡i

### Xem táº¥t cáº£ pods:
```bash
kubectl get pods -n bigdata
```

### Xem logs cá»§a má»™t pod:
```bash
kubectl logs -f <pod-name> -n bigdata
```

### Xem services:
```bash
kubectl get svc -n bigdata
```

### Describe pod (debug):
```bash
kubectl describe pod <pod-name> -n bigdata
```

### Truy cáº­p vÃ o container:
```bash
kubectl exec -it <pod-name> -n bigdata -- /bin/bash
```

---

## ğŸ”§ Cáº¥u hÃ¬nh quan trá»ng (ConfigMap)

File: `configmap/bigdata-config.yaml`

```yaml
HDFS_PATH: "hdfs://namenode:8020/data/ohlcv"
HDFS_PATH_MARKET: "hdfs://namenode:8020/data/market"
ES_HOST: "http://elasticsearch:9200"
ES_INDEX_BATCH_OHLCV_DAILY: "ohlcv_daily_v2"
ES_INDEX_BATCH_OHLCV_ANAYLYST: "ohlcv_analysis"
ES_INDEX_BATCH_MARKET: "market_data_v1"
ES_INDEX_SPEED_STOCK: "stock_intraday"
SPARK_MASTER: "spark://spark-master:7077"
KAFKA_BOOTSTRAP: "kafka:9092"
KAFKA_TOPIC_BATCH_OHLCV: "stock.ohlcv.raw"
KAFKA_TOPIC_BATCH_MARKET: "stock.market.raw"
KAFKA_TOPIC_SPEED_STOCK: "stock.market.speed.raw"
SYMBOLS: "FPT,VNM,VCB"
DATA_SOURCE: "VCI"
```

### Cáº­p nháº­t ConfigMap:
```bash
# Chá»‰nh sá»­a file
vim configmap/bigdata-config.yaml

# Apply changes
kubectl apply -f configmap/bigdata-config.yaml

# Restart pods Ä‘á»ƒ Ã¡p dá»¥ng config má»›i
kubectl rollout restart deployment <deployment-name> -n bigdata
```

---

## ğŸ¯ Workflows phá»• biáº¿n

### 1. Cháº¡y Batch Processing Pipeline hoÃ n chá»‰nh:

```bash
# Step 1: Crawl dá»¯ liá»‡u â†’ Kafka
kubectl create job --from=cronjob/crawler-job manual-crawler-$(date +%s) -n bigdata

# Step 2: Kafka â†’ HDFS
kubectl create job --from=cronjob/kafka-to-hdfs-ohlcv-job manual-k2h-$(date +%s) -n bigdata

# Step 3: Xá»­ lÃ½ Daily + Analyst
kubectl create job --from=cronjob/daily-ohlcv-job manual-daily-$(date +%s) -n bigdata
kubectl create job --from=cronjob/ohlcv-analysis-job manual-analyst-$(date +%s) -n bigdata
```

### 2. Kiá»ƒm tra Kafka topics:

```bash
# Exec vÃ o Kafka pod
kubectl exec -it <kafka-pod-name> -n bigdata -- /bin/bash

# List topics
kafka-topics --list --bootstrap-server localhost:9092

# Äá»c messages tá»« topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic stock.ohlcv.raw --from-beginning --max-messages 10
```

### 3. Kiá»ƒm tra HDFS:

```bash
# Exec vÃ o NameNode pod
kubectl exec -it <namenode-pod-name> -n bigdata -- /bin/bash

# List files trong HDFS
hdfs dfs -ls /data/ohlcv
hdfs dfs -ls /data/market

# Xem dung lÆ°á»£ng
hdfs dfs -du -h /data
```

### 4. Query Elasticsearch:

```bash
# Port-forward Elasticsearch
kubectl port-forward svc/elasticsearch 9200:9200 -n bigdata

# Tá»« mÃ¡y local
curl http://localhost:9200/_cat/indices?v
curl http://localhost:9200/ohlcv_daily_v2/_count
curl http://localhost:9200/ohlcv_daily_v2/_search?size=5
```

### 5. Truy cáº­p Spark UI:

```bash
# Port-forward Spark Master UI
kubectl port-forward svc/spark-master 8080:8080 -n bigdata

# Má»Ÿ browser: http://localhost:8080
```

---

## ğŸ³ Build Docker Images

TrÆ°á»›c khi deploy, cáº§n build cÃ¡c Docker images:

```bash
# Crawler
cd ../batch/crawler_batch
docker build -t crawler:latest .

# Daily OHLCV
cd ../batch/jobs/ohlcv/daily
docker build -t daily_ohlcv:latest .

# Analyst OHLCV
cd ../batch/jobs/ohlcv/analyst
docker build -t analyst_ohlcv:latest .

# MLlib
cd ../batch/jobs/ohlcv/mlib_evaluate
docker build -t mlib_evaluate:latest .

# Speed Crawler
cd ../speed/crawler_speed
docker build -t speed-crawler:latest .

# OHLCV Speed
cd ../speed/ohlcv
docker build -t ohlcv-speed:latest .
```

**LÆ°u Ã½:** Náº¿u dÃ¹ng private registry, cáº§n push images vÃ  update `image:` trong deployment files.

---

## ğŸ” Quáº£n lÃ½ Secrets

File: `secrets/airflow-secret.yaml`

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: airflow-secret
  namespace: bigdata
type: Opaque
data:
  postgres-password: <base64-encoded-password>
```

Táº¡o secret má»›i:
```bash
kubectl create secret generic my-secret \
  --from-literal=username=admin \
  --from-literal=password=secret123 \
  -n bigdata
```

---

## ğŸ“ˆ Scaling

### Scale Spark Workers:
```bash
kubectl scale deployment spark-worker --replicas=3 -n bigdata
```

### Scale Datanode:
```bash
kubectl scale deployment datanode --replicas=2 -n bigdata
```

### Horizontal Pod Autoscaler (HPA):
```bash
kubectl autoscale deployment spark-worker \
  --cpu-percent=70 --min=2 --max=5 -n bigdata
```

---

## ğŸ› Troubleshooting

### Pod khÃ´ng start Ä‘Æ°á»£c:
```bash
# Xem events
kubectl describe pod <pod-name> -n bigdata

# Xem logs
kubectl logs <pod-name> -n bigdata

# Xem logs cá»§a container init (náº¿u cÃ³)
kubectl logs <pod-name> -c <init-container-name> -n bigdata
```

### ImagePullBackOff error:
```bash
# Kiá»ƒm tra image name
kubectl describe pod <pod-name> -n bigdata | grep Image

# Kiá»ƒm tra imagePullSecrets (náº¿u dÃ¹ng private registry)
kubectl get secret -n bigdata
```

### CrashLoopBackOff:
```bash
# Xem logs trÆ°á»›c khi crash
kubectl logs <pod-name> --previous -n bigdata

# Kiá»ƒm tra liveness/readiness probe
kubectl describe pod <pod-name> -n bigdata | grep -A 5 Liveness
```

### Service khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c:
```bash
# Kiá»ƒm tra endpoints
kubectl get endpoints <service-name> -n bigdata

# Test connectivity tá»« pod khÃ¡c
kubectl run -it --rm debug --image=busybox --restart=Never -n bigdata -- sh
wget -O- http://kafka:9092
```

---

## ğŸ§¹ Dá»n dáº¹p

### XÃ³a toÃ n bá»™ namespace (cáº©n tháº­n!):
```bash
kubectl delete namespace bigdata
```

### XÃ³a tá»«ng component:
```bash
kubectl delete -f deployments/ -n bigdata
kubectl delete -f jobs/ -n bigdata
kubectl delete -f services/ -n bigdata
kubectl delete -f configmap/ -n bigdata
kubectl delete -f secrets/ -n bigdata
```

---

## ğŸ“š Tham kháº£o

- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)
- [Kubernetes Patterns](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/)
- [Spark on Kubernetes](https://spark.apache.org/docs/latest/running-on-kubernetes.html)