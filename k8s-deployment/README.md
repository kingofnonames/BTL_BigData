<!-- BTL_BigData Kubernetes Deployment
1ï¸âƒ£ YÃªu cáº§u

Minikube Ä‘Ã£ cÃ i vÃ  Ä‘ang cháº¡y.

Docker Desktop hoáº·c Docker daemon Ä‘ang cháº¡y.

CÃ¡c Docker images cho cÃ¡c job Ä‘Ã£ build sáºµn.

ThÆ° má»¥c dá»¯ liá»‡u tá»“n táº¡i:

./data/hdfs/namenode
./data/hdfs/datanode
./data/elasticsearch
./airflow/dags
./airflow/logs

2ï¸âƒ£ Cáº¥u trÃºc thÆ° má»¥c
k8s-deployment/
â”œâ”€â”€ configmap # Chá»©a cÃ¡c ConfigMap cho env variables
â”œâ”€â”€ secrets # Chá»©a cÃ¡c Secret (credentials)
â”œâ”€â”€ deployments # Chá»©a cÃ¡c Deployment YAML
â”œâ”€â”€ jobs # Chá»©a cÃ¡c Job YAML (batch jobs)
â””â”€â”€ services # Chá»©a cÃ¡c Service YAML Ä‘á»ƒ pod káº¿t ná»‘i

3ï¸âƒ£ Sá»­ dá»¥ng Docker daemon cá»§a Minikube

Náº¿u muá»‘n build Docker image trá»±c tiáº¿p trong Minikube, cháº¡y:

eval $(minikube -p minikube docker-env)

4ï¸âƒ£ Build Docker images

VÃ­ dá»¥ cÃ¡c job Spark/Python:

# analyst_ohlcv

docker build -t analyst_ohlcv:latest ./path_to_analyst_ohlcv

# daily_ohlcv

docker build -t daily_ohlcv:latest ./path_to_daily_ohlcv

# kafka_to_hdfs_ohlcv

docker build -t kafka_to_hdfs_ohlcv:latest ./path_to_kafka_to_hdfs_ohlcv

# kafka_to_hdfs_market

docker build -t kafka_to_hdfs_market:latest ./path_to_kafka_to_hdfs_market

# mlib_evaluate

docker build -t mlib_evaluate:latest ./path_to_mlib_evaluate

# ohlcv_speed

docker build -t ohlcv_speed:latest ./path_to_ohlcv_speed

# speed_crawler

docker build -t speed_crawler:latest ./path_to_speed_crawler

5ï¸âƒ£ Apply ConfigMap vÃ  Secret
kubectl apply -f configmap/bigdata-config.yaml
kubectl apply -f secrets/airflow-secret.yaml

ConfigMap chá»©a HDFS_PATH, Kafka bootstrap, Elasticsearch host/index, v.v.
Secret chá»©a credentials (náº¿u cÃ³, vÃ­ dá»¥ PostgreSQL cho Airflow).

6ï¸âƒ£ Deploy Services
kubectl apply -f services/

Services giÃºp cÃ¡c pod trong namespace bigdata káº¿t ná»‘i vá»›i nhau.

7ï¸âƒ£ Deploy Core Deployments
kubectl apply -f deployments/

Bao gá»“m:

Zookeeper & Kafka

HDFS Namenode & Datanode

Spark Master & Worker

Elasticsearch & Kibana

Airflow DB, Webserver, Scheduler

8ï¸âƒ£ Deploy Jobs / Batch Jobs
kubectl apply -f jobs/

Bao gá»“m cÃ¡c job:

analyst_ohlcv

daily_ohlcv

mlib_evaluate

kafka_to_hdfs_ohlcv

kafka_to_hdfs_market

ohlcv_speed

speed_crawler

Jobs sáº½ cháº¡y 1 láº§n vÃ  káº¿t thÃºc. Náº¿u muá»‘n cháº¡y láº¡i:

kubectl delete job <job-name> -n bigdata
kubectl apply -f jobs/<job-yaml>

9ï¸âƒ£ Kiá»ƒm tra tráº¡ng thÃ¡i

# Kiá»ƒm tra pods

kubectl get pods -n bigdata

# Kiá»ƒm tra services

kubectl get svc -n bigdata

# Xem logs cá»§a pod

kubectl logs <pod-name> -n bigdata

ğŸ”Ÿ Truy cáº­p Web UI

Airflow Webserver: http://<minikube-ip>:8080

Spark Master UI: http://<minikube-ip>:8080

Elasticsearch: http://<minikube-ip>:9200

Kibana: http://<minikube-ip>:5601

Láº¥y Minikube IP:

minikube ip

1ï¸âƒ£1ï¸âƒ£ Debug & Ghi chÃº

Sá»­a ConfigMap náº¿u cáº§n thay Ä‘á»•i HDFS path, Kafka topic, Elasticsearch index:

kubectl edit configmap bigdata-config -n bigdata

Xem chi tiáº¿t pod:

kubectl describe pod <pod-name> -n bigdata

Náº¿u pod khÃ´ng cháº¡y, kiá»ƒm tra logs:

kubectl logs <pod-name> -n bigdata

HostPath volumes sáº½ mount dá»¯ liá»‡u tá»« mÃ¡y local; Ä‘áº£m báº£o cÃ¡c thÆ° má»¥c dá»¯ liá»‡u tá»“n táº¡i trÆ°á»›c khi deploy. -->

BTL_BigData Kubernetes Deployment

1. YÃªu cáº§u

Minikube Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t vÃ  Ä‘ang cháº¡y.

Docker Desktop hoáº·c Docker daemon Ä‘ang cháº¡y.

Helm (tÃ¹y chá»n, náº¿u dÃ¹ng chart Ä‘á»ƒ quáº£n lÃ½).

Spark, Kafka, HDFS, Elasticsearch, Airflow Ä‘Æ°á»£c triá»ƒn khai qua Docker images Ä‘Ã£ build sáºµn. (docker-compose.yml trong thÆ° má»¥c docker-deployment (docker-compose up -d))

2. Cáº¥u trÃºc thÆ° má»¥c
   k8s-deployment/
   â”œâ”€â”€ configmap # Chá»©a cÃ¡c ConfigMap cho env variables
   â”œâ”€â”€ secrets # Chá»©a cÃ¡c Secret (vÃ­ dá»¥ credentials)
   â”œâ”€â”€ deployments # Chá»©a cÃ¡c Deployment YAML
   â”œâ”€â”€ jobs # Chá»©a cÃ¡c Job YAML (batch jobs)
   â””â”€â”€ services # Chá»©a cÃ¡c Service YAML Ä‘á»ƒ pod káº¿t ná»‘i

3. Build Docker images cho cÃ¡c job

Äi vÃ o thÆ° má»¥c chá»©a Dockerfile cá»§a tá»«ng job vÃ  build:

# VÃ­ dá»¥: build analyst_ohlcv

docker build -t analyst_ohlcv:latest ./path_to_analyst_ohlcv

# Build daily_ohlcv

docker build -t daily_ohlcv:latest ./path_to_daily_ohlcv

# Build kafka_to_hdfs_ohlcv

docker build -t kafka_to_hdfs_ohlcv:latest ./path_to_kafka_to_hdfs_ohlcv

# Build kafka_to_hdfs_market

docker build -t kafka_to_hdfs_market:latest ./path_to_kafka_to_hdfs_market

# Build mlib_evaluate

docker build -t mlib_evaluate:latest ./path_to_mlib_evaluate

# Build ohlcv_speed

docker build -t ohlcv_speed:latest ./path_to_ohlcv_speed

# Build speed_crawler

docker build -t speed_crawler:latest ./path_to_speed_crawler

Náº¿u dÃ¹ng Minikube Docker daemon, cháº¡y trÆ°á»›c:

eval $(minikube -p minikube docker-env)

4. Deploy ConfigMap vÃ  Secrets
   kubectl apply -f configmap/bigdata-config.yaml
   kubectl apply -f secrets/airflow-secret.yaml

5. Deploy Services
   kubectl apply -f services/

6. Deploy Core Deployments
   kubectl apply -f deployments/

Core deployments bao gá»“m:

Zookeeper, Kafka

HDFS Namenode & Datanode

Spark Master & Worker

Elasticsearch & Kibana

Airflow DB, Webserver, Scheduler

7. Deploy Jobs / Batch Spark Jobs
   kubectl apply -f jobs/

CÃ¡c jobs bao gá»“m:

analyst_ohlcv

daily_ohlcv

mlib_evaluate

kafka_to_hdfs_ohlcv

kafka_to_hdfs_market

ohlcv_speed

speed_crawler

Jobs sáº½ cháº¡y 1 láº§n vÃ  káº¿t thÃºc. Náº¿u muá»‘n cháº¡y láº¡i, xÃ³a job cÅ©:

kubectl delete job <job-name> -n bigdata
kubectl apply -f jobs/<job-yaml>

8. Kiá»ƒm tra tráº¡ng thÃ¡i

# Kiá»ƒm tra pods

kubectl get pods -n bigdata

# Kiá»ƒm tra services

kubectl get svc -n bigdata

# Xem logs cá»§a pod

kubectl logs <pod-name> -n bigdata

9. Truy cáº­p Web UI

Airflow Webserver: http://<minikube-ip>:8080

Spark Master UI: http://<minikube-ip>:8080

Elasticsearch: http://<minikube-ip>:9200

Kibana: http://<minikube-ip>:5601

Láº¥y Minikube IP:

minikube ip

10. Ghi chÃº

Táº¥t cáº£ cÃ¡c job Spark láº¥y config tá»« ConfigMap/Secret. Náº¿u cáº§n chá»‰nh HDFS path, Kafka topic, hoáº·c ES index, chá»‰nh trong configmap/bigdata-config.yaml.

Sá»­ dá»¥ng kubectl describe pod <pod> Ä‘á»ƒ debug náº¿u pod khÃ´ng cháº¡y.

CÃ¡c volume hostPath sáº½ mount dá»¯ liá»‡u tá»« mÃ¡y local, Ä‘áº£m báº£o thÆ° má»¥c tá»“n táº¡i:

./data/hdfs/namenode
./data/hdfs/datanode
./data/elasticsearch
./airflow/dags
./airflow/logs
