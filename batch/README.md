# Batch Layer â€“ Xá»­ lÃ½ dá»¯ liá»‡u chá»©ng khoÃ¡n theo lÃ´

Batch Layer chá»‹u trÃ¡ch nhiá»‡m thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u chá»©ng khoÃ¡n lá»‹ch sá»­ theo tá»«ng lÃ´ (batch), Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n vÃ  chÃ­nh xÃ¡c cá»§a dá»¯ liá»‡u.

---

## ğŸ“‹ Giá»›i thiá»‡u

Batch Layer trong kiáº¿n trÃºc Lambda Architecture thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥:

- **Thu tháº­p dá»¯ liá»‡u lá»‹ch sá»­**: Crawl dá»¯ liá»‡u OHLCV (Open, High, Low, Close, Volume) vÃ  Market Index tá»« cÃ¡c nguá»“n
- **LÆ°u trá»¯ vÃ o HDFS**: Äá»c dá»¯ liá»‡u tá»« Kafka, xá»­ lÃ½ báº±ng Spark vÃ  lÆ°u vÃ o HDFS theo Ä‘á»‹nh dáº¡ng Parquet
- **PhÃ¢n tÃ­ch vÃ  chá»‰ sá»‘ ká»¹ thuáº­t**: TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ nhÆ° SMA, EMA, RSI, MACD cho phÃ¢n tÃ­ch ká»¹ thuáº­t
- **Dá»± Ä‘oÃ¡n giÃ¡**: Sá»­ dá»¥ng Spark MLlib Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u
- **Äá»“ng bá»™ vÃ o Elasticsearch**: ÄÆ°a dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ o Elasticsearch Ä‘á»ƒ truy váº¥n nhanh

---

## ğŸ—ï¸ Cáº¥u trÃºc thÆ° má»¥c

```
batch/
â”œâ”€â”€ crawler_batch/              # Module thu tháº­p dá»¯ liá»‡u batch
â”‚   â”œâ”€â”€ config.py              # Cáº¥u hÃ¬nh crawler (symbols, date range, kafka)
â”‚   â”œâ”€â”€ kafka_producer.py      # Gá»­i dá»¯ liá»‡u vÃ o Kafka
â”‚   â”œâ”€â”€ main.py                # Entry point cháº¡y crawler
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ crawlers/
â”‚       â”œâ”€â”€ ohlcv_crawler.py   # Crawl dá»¯ liá»‡u giÃ¡ OHLCV
â”‚       â”œâ”€â”€ market_crawler.py  # Crawl chá»‰ sá»‘ thá»‹ trÆ°á»ng (VN-Index, HNX-Index)
â”‚       â””â”€â”€ fundamental_crawler.py  # Crawl dá»¯ liá»‡u cÆ¡ báº£n
â”‚
â””â”€â”€ jobs/                       # CÃ¡c job xá»­ lÃ½ dá»¯ liá»‡u vá»›i Spark
    â”œâ”€â”€ market/
    â”‚   â””â”€â”€ kafka_to_hdfs_market/
    â”‚       â”œâ”€â”€ kafka_to_hdfs_market.py  # Äá»c Kafka â†’ ghi HDFS (market data)
    â”‚       â”œâ”€â”€ Dockerfile
    â”‚       â””â”€â”€ requirements.txt
    â”‚
    â””â”€â”€ ohlcv/
        â”œâ”€â”€ kafka_to_hdfs_ohlcv/
        â”‚   â”œâ”€â”€ kafka_to_hdfs_ohlcv.py   # Äá»c Kafka â†’ ghi HDFS (OHLCV)
        â”‚   â”œâ”€â”€ Dockerfile
        â”‚   â””â”€â”€ requirements.txt
        â”‚
        â”œâ”€â”€ daily/
        â”‚   â”œâ”€â”€ daily_ohlcv.py           # Xá»­ lÃ½ OHLCV hÃ ng ngÃ y â†’ Elasticsearch
        â”‚   â”œâ”€â”€ Dockerfile
        â”‚   â””â”€â”€ requirements.txt
        â”‚
        â”œâ”€â”€ analyst/
        â”‚   â”œâ”€â”€ analyst_ohlcv.py         # TÃ­nh cÃ¡c chá»‰ sá»‘ ká»¹ thuáº­t (SMA, EMA, RSI, MACD)
        â”‚   â”œâ”€â”€ Dockerfile
        â”‚   â””â”€â”€ requirements.txt
        â”‚
        â””â”€â”€ mlib_evaluate/
            â”œâ”€â”€ mlib_evaluate.py         # Huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ (Linear Regression, Random Forest)
            â”œâ”€â”€ Dockerfile
            â””â”€â”€ requirements.txt
```

---

## âš™ï¸ CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. Crawler Batch (`crawler_batch/`)

**Chá»©c nÄƒng:**
- Thu tháº­p dá»¯ liá»‡u lá»‹ch sá»­ OHLCV tá»« VCI/TCBS qua thÆ° viá»‡n vnstock3
- Thu tháº­p chá»‰ sá»‘ thá»‹ trÆ°á»ng (VNINDEX, HNX-INDEX)
- Gá»­i dá»¯ liá»‡u vÃ o Kafka topics: `stock.ohlcv.raw`, `stock.market.raw`

**Cáº¥u hÃ¬nh chÃ­nh** (trong `config.py`):
```python
SYMBOLS = ["FPT", "VNM", "VCB"]  # Danh sÃ¡ch mÃ£ cá»• phiáº¿u
DATA_SOURCE = "VCI"               # Nguá»“n dá»¯ liá»‡u: VCI hoáº·c TCBS
START_DATE = "2024-01-01"         # NgÃ y báº¯t Ä‘áº§u crawl
END_DATE = "2024-12-31"           # NgÃ y káº¿t thÃºc
KAFKA_BOOTSTRAP = "kafka:9092"    # Kafka server
TOPIC_OHLCV_RAW = "stock.ohlcv.raw"
TOPIC_MARKET_RAW = "stock.market.raw"
```

**Cháº¡y crawler:**
```bash
cd crawler_batch
python main.py
```

---

### 2. Kafka to HDFS Jobs

#### a) `kafka_to_hdfs_ohlcv` - LÆ°u OHLCV vÃ o HDFS
- Äá»c dá»¯ liá»‡u tá»« Kafka topic `stock.ohlcv.raw`
- Parse JSON vÃ  chuyá»ƒn thÃ nh DataFrame
- LÆ°u vÃ o HDFS dáº¡ng Parquet, partition theo: `symbol`, `interval`, `trade_date`

**Cháº¡y job:**
```bash
spark-submit \
  --master spark://spark-master:7077 \
  kafka_to_hdfs_ohlcv.py
```

#### b) `kafka_to_hdfs_market` - LÆ°u Market data vÃ o HDFS
- Äá»c dá»¯ liá»‡u tá»« Kafka topic `stock.market.raw`
- LÆ°u vÃ o HDFS, partition theo: `index_code`, `trade_date`

**Cháº¡y job:**
```bash
spark-submit \
  --master spark://spark-master:7077 \
  kafka_to_hdfs_market.py
```

---

### 3. Daily OHLCV Processing (`daily/`)

**Chá»©c nÄƒng:**
- Äá»c dá»¯ liá»‡u OHLCV tá»« HDFS
- Flatten dá»¯ liá»‡u vÃ  chuáº©n hÃ³a Ä‘á»‹nh dáº¡ng ngÃ y
- Ghi vÃ o Elasticsearch index `ohlcv_daily_v2` Ä‘á»ƒ truy váº¥n nhanh

**Cháº¡y job:**
```bash
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
  daily_ohlcv.py
```

---

### 4. Analyst OHLCV (`analyst/`)

**Chá»©c nÄƒng:**
- TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ ká»¹ thuáº­t (Technical Indicators):
  - **SMA** (Simple Moving Average): Trung bÃ¬nh Ä‘á»™ng giáº£n Ä‘Æ¡n
  - **EMA** (Exponential Moving Average): Trung bÃ¬nh Ä‘á»™ng mÅ©
  - **RSI** (Relative Strength Index): Chá»‰ sá»‘ sá»©c máº¡nh tÆ°Æ¡ng Ä‘á»‘i
  - **MACD** (Moving Average Convergence Divergence): Há»™i tá»¥ phÃ¢n ká»³ trung bÃ¬nh Ä‘á»™ng
  - **Bollinger Bands**: Dáº£i Bollinger
- Xá»­ lÃ½ incremental: chá»‰ tÃ­nh toÃ¡n dá»¯ liá»‡u má»›i tá»« láº§n cháº¡y trÆ°á»›c
- LÆ°u káº¿t quáº£ vÃ o Elasticsearch index `ohlcv_analysis`

**Cháº¡y job:**
```bash
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
  analyst_ohlcv.py
```

---

### 5. MLlib Evaluate (`mlib_evaluate/`)

**Chá»©c nÄƒng:**
- Huáº¥n luyá»‡n mÃ´ hÃ¬nh Machine Learning dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u
- Sá»­ dá»¥ng dá»¯ liá»‡u OHLCV tá»« HDFS
- MÃ´ hÃ¬nh: Linear Regression vÃ  Random Forest Regressor
- Features: open, high, low, close, volume
- Label: giÃ¡ Ä‘Ã³ng cá»­a ngÃ y tiáº¿p theo (close_next)
- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh: RMSE, R2 Score

**Cháº¡y job:**
```bash
spark-submit \
  --master spark://spark-master:7077 \
  mlib_evaluate.py
```

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### YÃªu cáº§u há»‡ thá»‘ng:
- Python 3.9+
- Apache Spark 3.x
- Kafka 2.8+
- Hadoop HDFS 3.x
- Elasticsearch 8.x

### CÃ i Ä‘áº·t dependencies:

```bash
# Crawler
cd crawler_batch
pip install -r requirements.txt

# Jobs (má»—i job cÃ³ requirements.txt riÃªng)
cd jobs/ohlcv/daily
pip install -r requirements.txt
```

### Workflow hoÃ n chá»‰nh:

```bash
# BÆ°á»›c 1: Cháº¡y crawler Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u â†’ Kafka
cd crawler_batch
python main.py

# BÆ°á»›c 2: Chuyá»ƒn dá»¯ liá»‡u tá»« Kafka â†’ HDFS
spark-submit jobs/ohlcv/kafka_to_hdfs_ohlcv/kafka_to_hdfs_ohlcv.py
spark-submit jobs/market/kafka_to_hdfs_market/kafka_to_hdfs_market.py

# BÆ°á»›c 3: Xá»­ lÃ½ dá»¯ liá»‡u hÃ ng ngÃ y â†’ Elasticsearch
spark-submit --packages org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
  jobs/ohlcv/daily/daily_ohlcv.py

# BÆ°á»›c 4: TÃ­nh toÃ¡n chá»‰ sá»‘ ká»¹ thuáº­t â†’ Elasticsearch
spark-submit --packages org.elasticsearch:elasticsearch-spark-30_2.12:8.11.0 \
  jobs/ohlcv/analyst/analyst_ohlcv.py

# BÆ°á»›c 5: Huáº¥n luyá»‡n mÃ´ hÃ¬nh ML dá»± Ä‘oÃ¡n
spark-submit jobs/ohlcv/mlib_evaluate/mlib_evaluate.py
```

---

## ğŸ³ Cháº¡y vá»›i Docker

Má»—i module cÃ³ Dockerfile riÃªng:

```bash
# Build image crawler
cd crawler_batch
docker build -t crawler-batch:latest .

# Build image job
cd jobs/ohlcv/daily
docker build -t daily-ohlcv:latest .

# Cháº¡y container
docker run --rm --network bigdata-net crawler-batch:latest
```

---

## ğŸ“Š Luá»“ng dá»¯ liá»‡u (Data Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Crawler    â”‚  Thu tháº­p OHLCV, Market Index
â”‚   Batch     â”‚  
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ JSON
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka    â”‚  Topics: stock.ohlcv.raw, stock.market.raw
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafkaâ†’HDFS  â”‚  Spark Batch Job: Parse & Write Parquet
â”‚    Jobs     â”‚  
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HDFS     â”‚  LÆ°u trá»¯ dá»¯ liá»‡u dáº¡ng Parquet, partitioned
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚
       â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Daily    â”‚  â”‚  Analyst  â”‚  TÃ­nh chá»‰ sá»‘ ká»¹ thuáº­t
â”‚   OHLCV    â”‚  â”‚   OHLCV   â”‚  (SMA, EMA, RSI, MACD)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
       â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Elasticsearch      â”‚  Index: ohlcv_daily_v2, ohlcv_analysis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dashboard/Kibana     â”‚  Visualization & Query
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Biáº¿n mÃ´i trÆ°á»ng

CÃ¡c biáº¿n mÃ´i trÆ°á»ng quan trá»ng (cÃ³ thá»ƒ set qua ConfigMap trong K8s):

```bash
# Kafka
KAFKA_BOOTSTRAP=kafka:9092
KAFKA_TOPIC_BATCH_OHLCV=stock.ohlcv.raw
KAFKA_TOPIC_BATCH_MARKET=stock.market.raw

# HDFS
HDFS_PATH=hdfs://namenode:8020/data/ohlcv
HDFS_PATH_MARKET=hdfs://namenode:8020/data/market

# Elasticsearch
ES_HOST=http://elasticsearch:9200
ES_INDEX_BATCH_OHLCV_DAILY=ohlcv_daily_v2
ES_INDEX_BATCH_OHLCV_ANAYLYST=ohlcv_analysis

# Spark
SPARK_MASTER=spark://spark-master:7077

# Crawler Config
SYMBOLS=FPT,VNM,VCB
DATA_SOURCE=VCI
START_DATE=2024-01-01
END_DATE=2024-12-31
```

---

## ğŸ“ LÆ°u Ã½

- Crawler cháº¡y 1 láº§n/ngÃ y hoáº·c theo schedule tá»« Airflow
- Jobs Kafkaâ†’HDFS nÃªn cháº¡y sau khi crawler hoÃ n thÃ nh
- Analyst job xá»­ lÃ½ incremental Ä‘á»ƒ trÃ¡nh tÃ­nh toÃ¡n láº¡i toÃ n bá»™
- MLlib job cÃ³ thá»ƒ cháº¡y Ä‘á»‹nh ká»³ (1 tuáº§n/láº§n) Ä‘á»ƒ cáº­p nháº­t mÃ´ hÃ¬nh

---

## ğŸ› Troubleshooting

**Lá»—i: Kafka connection refused**
```bash
# Kiá»ƒm tra Kafka Ä‘Ã£ cháº¡y chÆ°a
kubectl get pods -n bigdata | grep kafka
# hoáº·c
docker ps | grep kafka
```

**Lá»—i: HDFS namenode not found**
```bash
# Kiá»ƒm tra HDFS namenode
hdfs dfsadmin -report
```

**Lá»—i: Elasticsearch index not found**
```bash
# Táº¡o index mapping trÆ°á»›c
curl -X PUT "http://elasticsearch:9200/ohlcv_daily_v2"
```

---

## ğŸ“š Tham kháº£o

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Kafka Python Client](https://kafka-python.readthedocs.io/)
- [vnstock3 Documentation](https://vnstock.site/)
- [Elasticsearch Spark Integration](https://www.elastic.co/guide/en/elasticsearch/hadoop/current/spark.html)